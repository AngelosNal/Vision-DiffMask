{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89770536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datamodules.image_classification import CIFAR10DataModule\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from models.interpretation import ImageInterpretationNet\n",
    "from torchvision.transforms.functional import normalize\n",
    "from utils.plot import smoothen, draw_mask_on_image, draw_heatmap_on_image\n",
    "from datamodules.transformations import UnNest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c708b7",
   "metadata": {},
   "source": [
    "# Load test data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18be2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = ViTForImageClassification.from_pretrained(\"tanlq/vit-base-patch16-224-in21k-finetuned-cifar10\")\n",
    "\n",
    "diffmask = ImageInterpretationNet.load_from_checkpoint('diffmask.ckpt')\n",
    "diffmask.set_vision_transformer(vit)\n",
    "\n",
    "feature_extractor=ViTFeatureExtractor.from_pretrained(\n",
    "    \"tanlq/vit-base-patch16-224-in21k-finetuned-cifar10\", return_tensors=\"pt\"\n",
    ")\n",
    "feature_extractor = UnNest(feature_extractor)\n",
    "\n",
    "dm = CIFAR10DataModule(feature_extractor=feature_extractor, batch_size=200)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "dt = iter(dm.test_dataloader())\n",
    "images, labels = next(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4f870",
   "metadata": {},
   "source": [
    "# Keep 9 samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64910d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "samples_per_class = 9\n",
    "images_ = None\n",
    "\n",
    "for i in range(10):\n",
    "    indices = list((labels == i).nonzero())[:samples_per_class]\n",
    "    if images_ is None:\n",
    "        images_ = images[indices,:,:,:]\n",
    "    else:\n",
    "        images_ = torch.cat([images_, images[indices, :, :, :]])\n",
    "\n",
    "images = images_\n",
    "rgb_images = [normalize(image, [-0.5, -0.5, -0.5], [2, 2, 2]).permute(1, 2, 0).clip(0, 1) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafe2c9",
   "metadata": {},
   "source": [
    "# Get the masks and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute masks\n",
    "diff_masks = diffmask.get_mask(images[:10])[\"mask\"].detach()\n",
    "for i in range(10, len(images), 10):\n",
    "    diff_masks = torch.cat([diff_masks, diffmask.get_mask(images[i:i+10])[\"mask\"].detach()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3198ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mask = lambda image, mask: draw_mask_on_image(image.permute(2, 0, 1), smoothen(mask)).permute(1, 2, 0).clip(0, 1).numpy()\n",
    "draw_heatmap = lambda image, mask: draw_heatmap_on_image(image.permute(2, 0, 1), smoothen(mask)).permute(1, 2, 0).clip(0, 1).numpy()\n",
    "    \n",
    "def plot_masks(rgbims, diffmasks, class_name):\n",
    "    rows = 3\n",
    "    columns = samples_per_class\n",
    "    fig, ax = plt.subplots(rows, columns, figsize=(25, 8))\n",
    "\n",
    "    # Remove axes\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "\n",
    "    font_size = 20\n",
    "    for j in range(samples_per_class):\n",
    "        if j==0:\n",
    "            ax[0, j].set_ylabel(\"Original Image\", fontsize=font_size)\n",
    "            ax[1, j].set_ylabel(\"Masked Image\", fontsize=font_size)\n",
    "            ax[2, j].set_ylabel(\"Heatmap\", fontsize=font_size)\n",
    "            \n",
    "        ax[0, j].imshow(rgbims[j])\n",
    "        ax[1, j].imshow(draw_mask(rgbims[j], diffmasks[j]))\n",
    "        ax[2, j].imshow(draw_heatmap(rgbims[j], diffmasks[j]))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(class_name + \".jpg\")\n",
    "    \n",
    "classes = ['planes', 'cars', 'birds', 'cats', 'deers', 'dogs', 'frogs', 'horses', 'ships', 'trucks']\n",
    "for j, i in enumerate(range(0, samples_per_class*10, samples_per_class)):\n",
    "    plot_masks(rgb_images[i:i + samples_per_class], diff_masks[i:i + samples_per_class], 'figures/'+classes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e9b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
