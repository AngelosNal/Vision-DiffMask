{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728c153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e33038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angelos/anaconda3/envs/dl2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "from datamodules.transformations import UnNest\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from models.interpretation import ImageInterpretationNet\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm.auto import tqdm\n",
    "from datamodules.image_classification import CIFAR10DataModule\n",
    "from datamodules.transformations import UnNest\n",
    "from math import sqrt\n",
    "from attributions.grad_cam import grad_cam\n",
    "from attributions.attention_rollout import attention_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434cfa9",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4370a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "vit = ViTForImageClassification.from_pretrained(\"tanlq/vit-base-patch16-224-in21k-finetuned-cifar10\").to(device)\n",
    "\n",
    "feature_extractor=ViTFeatureExtractor.from_pretrained(\n",
    "    \"tanlq/vit-base-patch16-224-in21k-finetuned-cifar10\", return_tensors=\"pt\"\n",
    ")\n",
    "feature_extractor = UnNest(feature_extractor)\n",
    "\n",
    "dm = CIFAR10DataModule(feature_extractor=feature_extractor, batch_size=10)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "dataloader = iter(dm.test_dataloader())\n",
    "\n",
    "images = next(dataloader)[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf41f4",
   "metadata": {},
   "source": [
    "# Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3265f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time for Grad-CAM 2.5233755111694336\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "grad_cam(images, vit, True if device=='cuda' else false)\n",
    "print(f\"Inference time for Grad-CAM {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f1db4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time for Attention Rollout 0.07604050636291504\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "attention_rollout(images=images, vit=vit, device=device)\n",
    "print(f\"Inference time for Attention Rollout {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74edb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time for DiffMask 0.12171101570129395\n"
     ]
    }
   ],
   "source": [
    "diffmask = ImageInterpretationNet.load_from_checkpoint('diffmask.ckpt').to(device)\n",
    "diffmask.set_vision_transformer(vit)\n",
    "\n",
    "start = time.time()\n",
    "diffmask.get_mask(images)[\"mask\"]\n",
    "print(f\"Inference time for DiffMask {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ca561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
