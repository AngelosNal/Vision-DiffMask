{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4890ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "from datamodules.transformations import UnNest\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from models.interpretation import ImageInterpretationNet\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm.auto import tqdm\n",
    "from datamodules.image_classification import CIFAR10DataModule\n",
    "from datamodules.transformations import UnNest\n",
    "from math import sqrt\n",
    "from attributions.grad_cam import grad_cam\n",
    "from attributions.attention_rollout import attention_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22ed2e",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "vit = ViTForImageClassification.from_pretrained(\"tanlq/vit-base-patch16-224-in21k-finetuned-cifar10\").to(device)\n",
    "\n",
    "feature_extractor=ViTFeatureExtractor.from_pretrained(\n",
    "    \"tanlq/vit-base-patch16-224-in21k-finetuned-cifar10\", return_tensors=\"pt\"\n",
    ")\n",
    "feature_extractor = UnNest(feature_extractor)\n",
    "\n",
    "dm = CIFAR10DataModule(feature_extractor=feature_extractor, batch_size=10)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "dataloader = iter(dm.test_dataloader())\n",
    "\n",
    "images = next(dataloader)[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49b277",
   "metadata": {},
   "source": [
    "# Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "grad_cam(images, vit, True if device=='cuda' else False)\n",
    "print(f\"Inference time for Grad-CAM {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb327689",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "attention_rollout(images=images, vit=vit, device=device)\n",
    "print(f\"Inference time for Attention Rollout {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c435cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffmask = ImageInterpretationNet.load_from_checkpoint('diffmask.ckpt').to(device)\n",
    "diffmask.set_vision_transformer(vit)\n",
    "\n",
    "start = time.time()\n",
    "diffmask.get_mask(images)[\"mask\"]\n",
    "print(f\"Inference time for DiffMask {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2e0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
